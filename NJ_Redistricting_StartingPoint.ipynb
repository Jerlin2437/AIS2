{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa0c8991",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d053be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9044994",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a92056",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417b53b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c0d7e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58a3d493-83fb-4965-bdcb-f1054425e86e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geojson in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: shapely in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (2.0.7)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (from shapely) (2.0.2)\n",
      "Requirement already satisfied: PyShp in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (3.0.2.post1)\n",
      "Requirement already satisfied: networkx in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (3.2.1)\n",
      "Collecting osmnx\n",
      "  Downloading osmnx-2.0.6-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting geopandas>=1.0.1 (from osmnx)\n",
      "  Downloading geopandas-1.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: networkx>=2.5 in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (from osmnx) (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (from osmnx) (2.0.2)\n",
      "Collecting pandas>=1.4 (from osmnx)\n",
      "  Downloading pandas-2.3.3-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Collecting requests>=2.27 (from osmnx)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: shapely>=2.0 in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (from osmnx) (2.0.7)\n",
      "Collecting pyogrio>=0.7.2 (from geopandas>=1.0.1->osmnx)\n",
      "  Downloading pyogrio-0.11.1-cp39-cp39-win_amd64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (from geopandas>=1.0.1->osmnx) (25.0)\n",
      "Collecting pyproj>=3.3.0 (from geopandas>=1.0.1->osmnx)\n",
      "  Downloading pyproj-3.6.1-cp39-cp39-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (from pandas>=1.4->osmnx) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.4->osmnx)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.4->osmnx)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting certifi (from pyogrio>=0.7.2->geopandas>=1.0.1->osmnx)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.17.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.27->osmnx)\n",
      "  Downloading charset_normalizer-3.4.4-cp39-cp39-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.27->osmnx)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.27->osmnx)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Downloading osmnx-2.0.6-py3-none-any.whl (101 kB)\n",
      "Downloading geopandas-1.0.1-py3-none-any.whl (323 kB)\n",
      "Downloading pandas-2.3.3-cp39-cp39-win_amd64.whl (11.4 MB)\n",
      "   ---------------------------------------- 0.0/11.4 MB ? eta -:--:--\n",
      "   ---------------------------------------  11.3/11.4 MB 88.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.4/11.4 MB 30.9 MB/s  0:00:00\n",
      "Downloading pyogrio-0.11.1-cp39-cp39-win_amd64.whl (19.2 MB)\n",
      "   ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "   ---------------------------------------  19.1/19.2 MB 109.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.2 MB 109.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.2 MB 109.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.2 MB 109.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.2 MB 109.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.2 MB 109.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.2 MB 109.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.2 MB 109.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.2 MB 109.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.2 MB 109.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.2 MB 109.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.2 MB 109.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.2 MB 109.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.2 MB 109.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.2/19.2 MB 6.4 MB/s  0:00:02\n",
      "Downloading pyproj-3.6.1-cp39-cp39-win_amd64.whl (6.1 MB)\n",
      "   ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.1/6.1 MB 31.0 MB/s  0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp39-cp39-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, urllib3, tzdata, idna, charset_normalizer, certifi, requests, pyproj, pyogrio, pandas, geopandas, osmnx\n",
      "\n",
      "   ----------------------------------------  0/12 [pytz]\n",
      "   ----------------------------------------  0/12 [pytz]\n",
      "   ----------------------------------------  0/12 [pytz]\n",
      "   --- ------------------------------------  1/12 [urllib3]\n",
      "   --- ------------------------------------  1/12 [urllib3]\n",
      "   --- ------------------------------------  1/12 [urllib3]\n",
      "   --- ------------------------------------  1/12 [urllib3]\n",
      "   --- ------------------------------------  1/12 [urllib3]\n",
      "   ------ ---------------------------------  2/12 [tzdata]\n",
      "   ------ ---------------------------------  2/12 [tzdata]\n",
      "   ------ ---------------------------------  2/12 [tzdata]\n",
      "   ------ ---------------------------------  2/12 [tzdata]\n",
      "   ---------- -----------------------------  3/12 [idna]\n",
      "   ------------- --------------------------  4/12 [charset_normalizer]\n",
      "   ---------------- -----------------------  5/12 [certifi]\n",
      "   -------------------- -------------------  6/12 [requests]\n",
      "   ----------------------- ----------------  7/12 [pyproj]\n",
      "   ----------------------- ----------------  7/12 [pyproj]\n",
      "   ----------------------- ----------------  7/12 [pyproj]\n",
      "   ----------------------- ----------------  7/12 [pyproj]\n",
      "   -------------------------- -------------  8/12 [pyogrio]\n",
      "   -------------------------- -------------  8/12 [pyogrio]\n",
      "   -------------------------- -------------  8/12 [pyogrio]\n",
      "   -------------------------- -------------  8/12 [pyogrio]\n",
      "   -------------------------- -------------  8/12 [pyogrio]\n",
      "   -------------------------- -------------  8/12 [pyogrio]\n",
      "   -------------------------- -------------  8/12 [pyogrio]\n",
      "   -------------------------- -------------  8/12 [pyogrio]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   ------------------------------ ---------  9/12 [pandas]\n",
      "   --------------------------------- ------ 10/12 [geopandas]\n",
      "   --------------------------------- ------ 10/12 [geopandas]\n",
      "   --------------------------------- ------ 10/12 [geopandas]\n",
      "   --------------------------------- ------ 10/12 [geopandas]\n",
      "   --------------------------------- ------ 10/12 [geopandas]\n",
      "   --------------------------------- ------ 10/12 [geopandas]\n",
      "   --------------------------------- ------ 10/12 [geopandas]\n",
      "   --------------------------------- ------ 10/12 [geopandas]\n",
      "   ------------------------------------ --- 11/12 [osmnx]\n",
      "   ------------------------------------ --- 11/12 [osmnx]\n",
      "   ---------------------------------------- 12/12 [osmnx]\n",
      "\n",
      "Successfully installed certifi-2025.11.12 charset_normalizer-3.4.4 geopandas-1.0.1 idna-3.11 osmnx-2.0.6 pandas-2.3.3 pyogrio-0.11.1 pyproj-3.6.1 pytz-2025.2 requests-2.32.5 tzdata-2025.2 urllib3-2.5.0\n",
      "Requirement already satisfied: pandas in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kweku\\documents\\ais2\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install geojson\n",
    "!pip install shapely\n",
    "!pip install PyShp\n",
    "!pip install networkx\n",
    "!pip install osmnx\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a7f250-1f24-4f02-832b-1df2dceaa50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import csv\n",
    "import ast\n",
    "import shapefile as shp\n",
    "from shapely.geometry import Polygon,shape,MultiPolygon\n",
    "import shapely.ops\n",
    "import warnings\n",
    "import math\n",
    "from collections import deque\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1549e7-0856-443a-aedc-df06d9caf33a",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad28b0c5-f5b6-4baf-9295-07dbff55df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isDistrictContiguous(district_num, assignment, contiguity_list, print_isolates=False, ignore_list=[]):\n",
    "    ## input:\n",
    "    ## district_num: the district number\n",
    "    ## assignment: the assignment from precinct to district\n",
    "    ## contiguity_list: the list of neighbors for each precinct, from the csv file\n",
    "    contiguity_list.columns = ['Precinct','Neighbors']\n",
    "    district_graph = nx.Graph() #creates an empty undirected graph\n",
    "    district_nodes = assignment[assignment['District']==district_num]['GEOID20'].tolist()\n",
    "    for i in ignore_list:\n",
    "        try:\n",
    "            district_nodes.remove(i)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    district_graph.add_nodes_from(district_nodes)\n",
    "    for id in district_nodes:\n",
    "        neighbors = ast.literal_eval(contiguity_list[contiguity_list['Precinct']==id]['Neighbors'].values.tolist()[0])\n",
    "        # needed to convert string to list because the csv encodes the list as a string\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor in district_nodes:\n",
    "                district_graph.add_edge(id,neighbor)\n",
    "    if(print_isolates):\n",
    "        print(list(nx.isolates(district_graph)))\n",
    "    return nx.is_connected(district_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "474da28a-35a4-4115-b19e-9439d1044e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistrictPopulations(assignment,data_file, num_district):\n",
    "    population = {}\n",
    "    for i in range (1,num_district+1):\n",
    "        population[i] = data_file[data_file['GEOID20'].isin(assignment[assignment['District']==i]['GEOID20'])]['Total_2020_Total'].sum()\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92c27697-04a7-4169-843b-ce2d98622efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistrictShape(district_id, assignment, boundaries):\n",
    "    list_precincts = assignment[assignment['District']==district_id]['GEOID20']\n",
    "    precinct_shapes = []\n",
    "    for i in list_precincts:\n",
    "        if shape(boundaries[i]).geom_type == 'Polygon':\n",
    "            precinct_shapes.append(Polygon(shape(boundaries[i])))\n",
    "        elif shape(boundaries[i]).geom_type == 'MultiPolygon':\n",
    "            precinct_shapes.append(MultiPolygon(shape(boundaries[i])))      \n",
    "    district_shape = shapely.ops.unary_union(precinct_shapes)\n",
    "    #print(district_shape)\n",
    "    return district_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5e8260f-2f6a-497e-8ff6-51dd9a767180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_compactness(geom): # Polsby-Popper\n",
    "    p = geom.length\n",
    "    a = geom.area    \n",
    "    return (4*np.pi*a)/(p*p)\n",
    "\n",
    "def box_reock_compactness(geom): # Reock on a rectangle bounding box\n",
    "    a = geom.area \n",
    "    bb = geom.bounds # bounds gives you the minimum bounding box (rectangle)\n",
    "    bba = abs(bb[0]-bb[2])*abs(bb[1]-bb[3])\n",
    "    return a/bba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959227a9-93f8-47fa-87ef-02037facafb9",
   "metadata": {},
   "source": [
    "# This Notebook will help you get started on NJ\n",
    "The data is in Canvas, you should upload it to your Google Drive first (if using Colab), or local filesystem (if using Jupyter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69143d08-629d-436a-8687-7a5d3bcb5aa3",
   "metadata": {},
   "source": [
    "### This is the current assignment of precinct to congressional districts (12 of them for NJ)\n",
    "Note that the map shown in DRA is slightly different. This is because some precincts are split in the real assignment, and some additional precinct are created to handle special situations such as prisoners and overseas citizens. You can ignore this for the class project and just use the data and functions provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c0c2b03-9b2f-46c5-b619-0709ca555c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID20</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34033020001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34033001501</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34033042009</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34033000703</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34033042001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>34039045302</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>34039045303</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6358</th>\n",
       "      <td>34039045404</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>34039045801</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6360</th>\n",
       "      <td>34039045802</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6361 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID20  District\n",
       "0     34033020001         2\n",
       "1     34033001501         2\n",
       "2     34033042009         2\n",
       "3     34033000703         2\n",
       "4     34033042001         2\n",
       "...           ...       ...\n",
       "6356  34039045302         7\n",
       "6357  34039045303         7\n",
       "6358  34039045404         7\n",
       "6359  34039045801         7\n",
       "6360  34039045802         7\n",
       "\n",
       "[6361 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nj_current_assignment = pd.read_csv('Map_Data/precinct-assignments-congress-nj.csv')\n",
    "nj_current_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6bce06-2f20-4f82-959e-a95f91e25ba5",
   "metadata": {},
   "source": [
    "### This is the current demographic and voter data\n",
    "The data has a lot of attributes that lists voters of different demographics and parties in different elections. You can look at the data Dictionary on Canvas to get details. For this recitation we will only keep votes from the 2020  presidential election and the total 2020 population counts. You can use additional columns (e.g., Governor's elections results, voting age (VAP) population counts, or the composite Dem/Rep score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d13a23f-3b65-4852-a42d-3a87867f3361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID20</th>\n",
       "      <th>District</th>\n",
       "      <th>Total_2020_Pres</th>\n",
       "      <th>Dem_2020_Pres</th>\n",
       "      <th>Rep_2020_Pres</th>\n",
       "      <th>Total_2020_Total</th>\n",
       "      <th>White_2020_Total</th>\n",
       "      <th>Hispanic_2020_Total</th>\n",
       "      <th>Black_2020_Total</th>\n",
       "      <th>Asian_2020_Total</th>\n",
       "      <th>Native_2020_Total</th>\n",
       "      <th>Pacific_2020_Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34001005101</td>\n",
       "      <td>2</td>\n",
       "      <td>876</td>\n",
       "      <td>393</td>\n",
       "      <td>472</td>\n",
       "      <td>1240</td>\n",
       "      <td>946</td>\n",
       "      <td>128</td>\n",
       "      <td>102</td>\n",
       "      <td>66</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34001005102</td>\n",
       "      <td>2</td>\n",
       "      <td>852</td>\n",
       "      <td>450</td>\n",
       "      <td>388</td>\n",
       "      <td>1913</td>\n",
       "      <td>1331</td>\n",
       "      <td>211</td>\n",
       "      <td>286</td>\n",
       "      <td>84</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34001005103</td>\n",
       "      <td>2</td>\n",
       "      <td>1206</td>\n",
       "      <td>517</td>\n",
       "      <td>672</td>\n",
       "      <td>1760</td>\n",
       "      <td>1375</td>\n",
       "      <td>177</td>\n",
       "      <td>78</td>\n",
       "      <td>106</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34001005201</td>\n",
       "      <td>2</td>\n",
       "      <td>828</td>\n",
       "      <td>348</td>\n",
       "      <td>469</td>\n",
       "      <td>1311</td>\n",
       "      <td>906</td>\n",
       "      <td>168</td>\n",
       "      <td>150</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34001005202</td>\n",
       "      <td>2</td>\n",
       "      <td>868</td>\n",
       "      <td>579</td>\n",
       "      <td>282</td>\n",
       "      <td>1892</td>\n",
       "      <td>537</td>\n",
       "      <td>336</td>\n",
       "      <td>598</td>\n",
       "      <td>450</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>34041115002</td>\n",
       "      <td>7</td>\n",
       "      <td>606</td>\n",
       "      <td>182</td>\n",
       "      <td>418</td>\n",
       "      <td>737</td>\n",
       "      <td>714</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>34041115003</td>\n",
       "      <td>7</td>\n",
       "      <td>617</td>\n",
       "      <td>187</td>\n",
       "      <td>418</td>\n",
       "      <td>934</td>\n",
       "      <td>820</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6358</th>\n",
       "      <td>34041115004</td>\n",
       "      <td>7</td>\n",
       "      <td>478</td>\n",
       "      <td>160</td>\n",
       "      <td>308</td>\n",
       "      <td>697</td>\n",
       "      <td>602</td>\n",
       "      <td>66</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>34041115005</td>\n",
       "      <td>7</td>\n",
       "      <td>592</td>\n",
       "      <td>201</td>\n",
       "      <td>381</td>\n",
       "      <td>930</td>\n",
       "      <td>831</td>\n",
       "      <td>47</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6360</th>\n",
       "      <td>34041115006</td>\n",
       "      <td>7</td>\n",
       "      <td>464</td>\n",
       "      <td>138</td>\n",
       "      <td>319</td>\n",
       "      <td>777</td>\n",
       "      <td>699</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6361 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID20  District  Total_2020_Pres  Dem_2020_Pres  Rep_2020_Pres  \\\n",
       "0     34001005101         2              876            393            472   \n",
       "1     34001005102         2              852            450            388   \n",
       "2     34001005103         2             1206            517            672   \n",
       "3     34001005201         2              828            348            469   \n",
       "4     34001005202         2              868            579            282   \n",
       "...           ...       ...              ...            ...            ...   \n",
       "6356  34041115002         7              606            182            418   \n",
       "6357  34041115003         7              617            187            418   \n",
       "6358  34041115004         7              478            160            308   \n",
       "6359  34041115005         7              592            201            381   \n",
       "6360  34041115006         7              464            138            319   \n",
       "\n",
       "      Total_2020_Total  White_2020_Total  Hispanic_2020_Total  \\\n",
       "0                 1240               946                  128   \n",
       "1                 1913              1331                  211   \n",
       "2                 1760              1375                  177   \n",
       "3                 1311               906                  168   \n",
       "4                 1892               537                  336   \n",
       "...                ...               ...                  ...   \n",
       "6356               737               714                   11   \n",
       "6357               934               820                   60   \n",
       "6358               697               602                   66   \n",
       "6359               930               831                   47   \n",
       "6360               777               699                   30   \n",
       "\n",
       "      Black_2020_Total  Asian_2020_Total  Native_2020_Total  \\\n",
       "0                  102                66                 24   \n",
       "1                  286                84                 38   \n",
       "2                   78               106                 20   \n",
       "3                  150                64                 50   \n",
       "4                  598               450                 25   \n",
       "...                ...               ...                ...   \n",
       "6356                 3                 8                  0   \n",
       "6357                26                10                 14   \n",
       "6358                16                 4                  5   \n",
       "6359                27                11                 12   \n",
       "6360                27                 9                 10   \n",
       "\n",
       "      Pacific_2020_Total  \n",
       "0                      0  \n",
       "1                      4  \n",
       "2                      2  \n",
       "3                      5  \n",
       "4                      1  \n",
       "...                  ...  \n",
       "6356                   0  \n",
       "6357                   0  \n",
       "6358                   0  \n",
       "6359                   0  \n",
       "6360                   0  \n",
       "\n",
       "[6361 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nj_precinct_data = pd.read_csv('Map_Data/precinct-data-congress-nj.csv')\n",
    "keepcolumns = ['GEOID20','District','Total_2020_Pres','Dem_2020_Pres','Rep_2020_Pres','Total_2020_Total','White_2020_Total','Hispanic_2020_Total','Black_2020_Total','Asian_2020_Total','Native_2020_Total','Pacific_2020_Total']\n",
    "nj_precinct_data = nj_precinct_data[keepcolumns]\n",
    "nj_precinct_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e75d5-6d29-4ab2-ab58-39c67f8b79f1",
   "metadata": {},
   "source": [
    "### This is the precinct boundary data (uses shapely)\n",
    "\n",
    "This is data that represents the geography of the districts. It is needed to test for contiguity, or for any districting partitioning method based on geography. The data is in Shapely format. Each district is represented as a set of points that are connected to create the district shape (in the long/lat coordinates). Shapely geometric functions can be used to compare the shapes. These can be quite inefficient to run, so I am also providing you a pre-computed index that, for each district, lists the districts that are contiguous to it. You can see the code to generate the index in Contiguity.ipynb.\n",
    "\n",
    "To manipulate the shapes, cast them into Shapely Polygons (see example below) and you can use the Polygon properties and functions: https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html#shapely.Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd3dbde7-e314-4fe0-9861-969d96e13645",
   "metadata": {},
   "outputs": [],
   "source": [
    "shpfile = 'Map_Data/nj_vtd_2020_bound/nj_vtd_2020_bound.shp'\n",
    "dbffile = 'Map_Data/nj_vtd_2020_bound/nj_vtd_2020_bound.dbf'\n",
    "shxfile = 'Map_Data/nj_vtd_2020_bound/nj_vtd_2020_bound.shx'\n",
    "\n",
    "\n",
    "shpfile = shp.Reader(shp=shpfile, shx=shxfile, dbf=dbffile)\n",
    "nj_precinct_boundaries={}\n",
    "for sr in shpfile.iterShapeRecords():\n",
    "    geom = sr.shape # get geo bit\n",
    "    rec = sr.record # get db fields\n",
    "    nj_precinct_boundaries[rec[3]]=geom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a473b-0936-4c0e-93cc-850329eaa553",
   "metadata": {},
   "source": [
    "### This is the precinct boundary data \n",
    "\n",
    "This use the contiguity index I have pre-computed using Contiguity.ipynb, that is stored in Contiguity_nj.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51c9f089-caad-45b3-b795-71793bcfedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nj_contiguity = pd.read_csv('Contiguity_nj.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e2c4cda-bb3c-4392-9df0-5e075c19c27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District 1 True\n",
      "District 2 True\n",
      "District 3 True\n",
      "District 4 True\n",
      "District 5 True\n",
      "District 6 True\n",
      "District 7 True\n",
      "District 8 True\n",
      "District 9 True\n",
      "District 10 True\n",
      "District 11 True\n",
      "District 12 True\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,13):\n",
    "    print(\"District \"+str(i)+\" \"+str(isDistrictContiguous(i, nj_current_assignment, nj_contiguity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96bad083-6853-462f-be62-38ff2f84e2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 PP : 0.41768102211569347\n",
      "D1 BR : 0.45075813446417157\n",
      "D2 PP : 0.2632665176502347\n",
      "D2 BR : 0.38278056561756263\n",
      "D3 PP : 0.2280937682959879\n",
      "D3 BR : 0.38134920642809134\n",
      "D4 PP : 0.24812480573284196\n",
      "D4 BR : 0.5390173747196018\n",
      "D5 PP : 0.2410116694999733\n",
      "D5 BR : 0.36320426268176653\n",
      "D6 PP : 0.14677124653853732\n",
      "D6 BR : 0.32853496486220907\n",
      "D7 PP : 0.20246375771704353\n",
      "D7 BR : 0.44049249082841035\n",
      "D8 PP : 0.11227347882175574\n",
      "D8 BR : 0.36670629634952656\n",
      "D9 PP : 0.1683197710884751\n",
      "D9 BR : 0.29705227593212374\n",
      "D10 PP : 0.12061263370064262\n",
      "D10 BR : 0.34528827672774703\n",
      "D11 PP : 0.22236600778446886\n",
      "D11 BR : 0.5557086439792166\n",
      "D12 PP : 0.1620092442171186\n",
      "D12 BR : 0.38520439164401626\n"
     ]
    }
   ],
   "source": [
    "#Compactness of the current assignment\n",
    "for district in range(1,13):\n",
    "    print(\"D\"+str(district)+\" PP : \"+str(pp_compactness(getDistrictShape(district,nj_current_assignment,nj_precinct_boundaries))))\n",
    "    print(\"D\"+str(district)+\" BR : \"+str(box_reock_compactness(getDistrictShape(district,nj_current_assignment,nj_precinct_boundaries))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f43f2ef1-b4be-4c73-b87a-f6e9f6e9b3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: np.int64(775340), 2: np.int64(778354), 3: np.int64(778489), 4: np.int64(767834), 5: np.int64(774454), 6: np.int64(778516), 7: np.int64(785173), 8: np.int64(800074), 9: np.int64(766863), 10: np.int64(746178), 11: np.int64(769523), 12: np.int64(768196)}\n"
     ]
    }
   ],
   "source": [
    "# District Population of the current assignment\n",
    "print(getDistrictPopulations(nj_current_assignment,nj_precinct_data, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e696388-313f-4090-9035-09a7da258a19",
   "metadata": {},
   "source": [
    "# A simple geographical  redistricting strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ced817-48c2-4b56-8a46-c274e5b9ff7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can create a simple geopgraphical map, like we did for NH. In this case, we have 12 districts, so let's splitting the district in half North/South, and in 6th  East/West. \n",
    "New Hampshire's bounding box is (-75.559614,38.928519,-73.893979,41.357423) (https://anthonylouisdagostino.com/bounding-boxes-for-all-us-states/)\n",
    "So let's start by splitting the state approximately though the middle longitude (-74.72) : everything west of longitude -71.583934 is in odd Districts, everything east is in even Districts. We will use the precinct centroids to assign them. Then we will divide each half per latitude on the ranges  (38.92, 39.3, 39.7, 40.1, 40.5,40.9,41.35)\n",
    "Import the Map to DRA to look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da30c782-b466-47d7-bb37-78b3cad6bd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nj_longlat_assignment = nj_current_assignment.copy()\n",
    "nj_longlat_assignment['District'] = 0\n",
    "for index, row in nj_longlat_assignment.iterrows():\n",
    "    try:\n",
    "        if shape(nj_precinct_boundaries[row['GEOID20']]).geom_type == 'Polygon':\n",
    "            centroid = Polygon(shape(nj_precinct_boundaries[row['GEOID20']])).centroid\n",
    "        elif shape(nj_precinct_boundaries[row['GEOID20']]).geom_type == 'MultiPolygon':\n",
    "            centroid = MultiPolygon(shape(nj_precinct_boundaries[row['GEOID20']])).centroid\n",
    "        else:\n",
    "            print(shape(nj_precinct_boundaries[row['GEOID20']]).geom_type)\n",
    "            pass\n",
    "        if centroid.x <= -74.72:\n",
    "            if centroid.y <= 39.3:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 1\n",
    "            elif centroid.y <= 39.7:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 3\n",
    "            elif centroid.y <= 40.1:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 5\n",
    "            elif centroid.y <= 40.5:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 7\n",
    "            elif centroid.y <= 40.9:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 9\n",
    "            else:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 11\n",
    "        else:\n",
    "            if centroid.y <= 39.3:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 2\n",
    "            elif centroid.y <= 39.7:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 4\n",
    "            elif centroid.y <= 40.1:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 6\n",
    "            elif centroid.y <= 40.5:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 8\n",
    "            elif centroid.y <= 40.9:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 10\n",
    "            else:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 12\n",
    "    except KeyError: \n",
    "        pass\n",
    "#print(nh_longitude_assignment)\n",
    "nj_longlat_assignment.to_csv('Recitation maps/nj_longlat_map.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb00508f-3df2-487c-90ac-56a7af050c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 PP : 0.24444322502174795\n",
      "D1 BR : 0.39921574154934536\n",
      "D2 PP : 0.21732375139633123\n",
      "D2 BR : 0.3033805826444085\n",
      "D3 PP : 0.3012927570664991\n",
      "D3 BR : 0.7281613087250183\n",
      "D4 PP : 0.3019375759906228\n",
      "D4 BR : 0.6388831361756292\n",
      "D5 PP : 0.29897783517755583\n",
      "D5 BR : 0.5136294328843819\n",
      "D6 PP : 0.22596255307162377\n",
      "D6 BR : 0.5362987383285662\n",
      "D7 PP : 0.21866681223528045\n",
      "D7 BR : 0.4337413755961903\n",
      "D8 PP : 0.3513739185552307\n",
      "D8 BR : 0.82797734690796\n",
      "D9 PP : 0.37261194943216025\n",
      "D9 BR : 0.7269867982048943\n",
      "D10 PP : 0.28764401412152446\n",
      "D10 BR : 0.6900841778845721\n",
      "D11 PP : 0.34638282192061104\n",
      "D11 BR : 0.47137706735305646\n",
      "D12 PP : 0.318631303145351\n",
      "D12 BR : 0.5828294919378438\n"
     ]
    }
   ],
   "source": [
    "#Compactness of this Longlat assignment\n",
    "for district in range(1,13):\n",
    "    print(\"D\"+str(district)+\" PP : \"+str(pp_compactness(getDistrictShape(district,nj_longlat_assignment,nj_precinct_boundaries))))\n",
    "    print(\"D\"+str(district)+\" BR : \"+str(box_reock_compactness(getDistrictShape(district,nj_longlat_assignment,nj_precinct_boundaries))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "265c674a-6122-4440-a87a-9b5b4250f242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: np.int64(80406), 2: np.int64(22492), 3: np.int64(317218), 4: np.int64(274411), 5: np.int64(1124427), 6: np.int64(563593), 7: np.int64(244052), 8: np.int64(1471840), 9: np.int64(230117), 10: np.int64(3848094), 11: np.int64(61026), 12: np.int64(1051318)}\n"
     ]
    }
   ],
   "source": [
    "# District Population of this longlat assignment\n",
    "print(getDistrictPopulations(nj_longlat_assignment,nj_precinct_data, 12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f943977-f3a0-41b8-930e-6e26d74092f2",
   "metadata": {},
   "source": [
    "# Now create your own redistricting maps\n",
    "Remember to check for contiguity, and to ensure that the population of the districts are balanced (which is not the case in the example above.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840daff",
   "metadata": {},
   "source": [
    "## Fair Map Seeding Algorithm\n",
    "\n",
    "This section implements the seeding algorithm for the fair map. The goal is to select 12 initial seed precincts (one per district) that are:\n",
    "- Geographically spread out across the state\n",
    "- Have population sizes initially close to the average precinct population\n",
    "- Consider demographic trends and try to pair demographic groups \n",
    "- Not biased towards any political party \n",
    "- Located in areas that allow for compact district growth\n",
    "\n",
    "- Since final population of each district should be around NJPopulation/12.\n",
    "- The seed population of each district should be 10% of NJ Population/12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "830bfb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precinct_centroid(geoid, boundaries):\n",
    "    \"\"\"Get the centroid coordinates for a single precinct.\"\"\"\n",
    "    try:\n",
    "        if shape(boundaries[geoid]).geom_type == 'Polygon':\n",
    "            centroid = Polygon(shape(boundaries[geoid])).centroid\n",
    "        elif shape(boundaries[geoid]).geom_type == 'MultiPolygon':\n",
    "            centroid = MultiPolygon(shape(boundaries[geoid])).centroid\n",
    "        else:\n",
    "            return None\n",
    "        return (centroid.x, centroid.y)  # (longitude, latitude)\n",
    "    except (KeyError, Exception):\n",
    "        return None\n",
    "\n",
    "def get_district_centroid(district_id, assignment, boundaries):\n",
    "    \"\"\"Get the centroid coordinates for a district (all precincts in that district).\"\"\"\n",
    "    district_precincts = assignment[assignment['District'] == district_id]['GEOID20'].tolist()\n",
    "    precinct_centroids = []\n",
    "    for geoid in district_precincts:\n",
    "        centroid = get_precinct_centroid(geoid, boundaries)\n",
    "        if centroid:\n",
    "            precinct_centroids.append(centroid)\n",
    "    \n",
    "    if not precinct_centroids:\n",
    "        return None\n",
    "    \n",
    "    # Calculate average centroid (simple approach)\n",
    "    avg_lon = sum(c[0] for c in precinct_centroids) / len(precinct_centroids)\n",
    "    avg_lat = sum(c[1] for c in precinct_centroids) / len(precinct_centroids)\n",
    "    return (avg_lon, avg_lat)\n",
    "\n",
    "def get_precinct_neighbors(geoid, contiguity_df):\n",
    "    \"\"\"Get the list of neighboring precincts for a given precinct.\"\"\"\n",
    "    df = contiguity_df.copy()\n",
    "    df.columns = ['Precinct', 'Neighbors']\n",
    "    try:\n",
    "        neighbors_str = df[df['Precinct'] == geoid]['Neighbors'].values[0]\n",
    "        return ast.literal_eval(neighbors_str)\n",
    "    except (KeyError, IndexError, ValueError):\n",
    "        return []\n",
    "\n",
    "\n",
    "total_nj_population = nj_precinct_data['Total_2020_Total'].sum()\n",
    "avg_district_population = total_nj_population / 12\n",
    "advisedSeedPopulation = avg_district_population * 0.10\n",
    "\n",
    "\n",
    "def select_population_balanced_seeds(precinct_data, boundaries, contiguity_df, num_districts=12):\n",
    "    import pandas as pd\n",
    "    import math\n",
    "    \n",
    "    # Build coordinates for every precinct from shapefile centroids\n",
    "    coords = {}\n",
    "    for geoid in precinct_data['GEOID20']:\n",
    "        centroid = get_precinct_centroid(geoid, boundaries)\n",
    "        if centroid is not None:\n",
    "            coords[geoid] = centroid  # (lon, lat)\n",
    "\n",
    "    # Filter precinct_data to only those with valid centroids\n",
    "    precinct_data = precinct_data[precinct_data['GEOID20'].isin(coords.keys())].copy()\n",
    "    \n",
    "    # Prepare candidate seeds with basic filtering like before\n",
    "    avg_precint_pop = precinct_data['Total_2020_Total'].mean()\n",
    "    pop_low = avg_precint_pop * 0.5\n",
    "    pop_high = avg_precint_pop * 1.5\n",
    "\n",
    "    def is_good_seed_candidate(row):\n",
    "        geoid = row['GEOID20']\n",
    "        pop = row['Total_2020_Total']\n",
    "        if pop <= 0:\n",
    "            return False\n",
    "        neighbors = get_precinct_neighbors(geoid, contiguity_df)\n",
    "        if len(neighbors) == 0:\n",
    "            return False\n",
    "        if not (pop_low <= pop <= pop_high):\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    candidates = precinct_data[precinct_data.apply(is_good_seed_candidate, axis=1)].copy()\n",
    "    if candidates.empty:\n",
    "        # fallback to any with neighbors\n",
    "        candidates = precinct_data[precinct_data['GEOID20'].map(\n",
    "            lambda g: len(get_precinct_neighbors(g, contiguity_df)) > 0\n",
    "        )].copy()\n",
    "\n",
    "    # Add lon/lat columns\n",
    "    candidates['lon'] = candidates['GEOID20'].map(lambda g: coords[g][0])\n",
    "    candidates['lat'] = candidates['GEOID20'].map(lambda g: coords[g][1])\n",
    "\n",
    "    # Calculate center of candidates for initial seed pick\n",
    "    mean_lon = candidates['lon'].mean()\n",
    "    mean_lat = candidates['lat'].mean()\n",
    "\n",
    "    def euclidean(p1, p2):\n",
    "        return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "\n",
    "    seeds = []\n",
    "    assigned_pop = 0\n",
    "    total_pop = candidates['Total_2020_Total'].sum()\n",
    "    ideal_seed_pop = total_pop / num_districts\n",
    "\n",
    "    # Select the first seed: closest to center\n",
    "    candidates['dist_to_center'] = ((candidates['lon'] - mean_lon)**2 + \n",
    "                                    (candidates['lat'] - mean_lat)**2).pow(0.5)\n",
    "    first_seed = candidates.sort_values('dist_to_center').iloc[0]\n",
    "    seeds.append(first_seed['GEOID20'])\n",
    "    assigned_pop += first_seed['Total_2020_Total']\n",
    "    candidates = candidates[candidates['GEOID20'] != first_seed['GEOID20']]\n",
    "\n",
    "    # Now select remaining seeds balancing distance and population:\n",
    "    while len(seeds) < num_districts:\n",
    "        # Compute for each candidate:\n",
    "        # - min distance to existing seeds (to spread geographically)\n",
    "        # - difference of candidate pop to ideal_seed_pop (to balance pop)\n",
    "\n",
    "        weight_pop = 0.9\n",
    "        weight_dist = 1 - weight_pop\n",
    "        max_dist = candidates['lon'].max() - candidates['lon'].min()  # rough max lon range as proxy for max distance\n",
    "        max_pop_diff = candidates['Total_2020_Total'].max() - candidates['Total_2020_Total'].min()\n",
    "        def score_candidate(row):\n",
    "            dist_to_seed = min(euclidean(coords[row['GEOID20']], coords[s]) for s in seeds)\n",
    "            pop_diff = abs(row['Total_2020_Total'] - ideal_seed_pop)\n",
    "\n",
    "            dist_norm = dist_to_seed / max_dist if max_dist > 0 else 0\n",
    "            pop_norm = pop_diff / max_pop_diff if max_pop_diff > 0 else 0\n",
    "\n",
    "            return weight_dist * dist_norm - weight_pop * pop_norm\n",
    "\n",
    "\n",
    "        candidates['score'] = candidates.apply(score_candidate, axis=1)\n",
    "        next_seed = candidates.sort_values('score', ascending=False).iloc[0]\n",
    "\n",
    "        seeds.append(next_seed['GEOID20'])\n",
    "        assigned_pop += next_seed['Total_2020_Total']\n",
    "        candidates = candidates[candidates['GEOID20'] != next_seed['GEOID20']]\n",
    "\n",
    "    return seeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbbee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import ast\n",
    "import math\n",
    "\n",
    "def round_robin_balanced(\n",
    "        assignment,\n",
    "        contiguity_df,\n",
    "        seed_geoids,\n",
    "        precinct_data,\n",
    "        district_ids=None,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Round-robin flood fill that preserves contiguity and balances populations.\n",
    "    This is the *population-aware upgrade* of your original fast algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- PREP ---\n",
    "    assignment = assignment.copy()\n",
    "    assignment['District'] = 0\n",
    "\n",
    "    if district_ids is None:\n",
    "        K = len(seed_geoids)\n",
    "        district_ids = list(range(1, K+1))\n",
    "    else:\n",
    "        K = len(district_ids)\n",
    "\n",
    "    # neighbor map\n",
    "    cont = contiguity_df.copy()\n",
    "    cont.columns = ['Precinct', 'Neighbors']\n",
    "    neigh_map = {}\n",
    "    for p, ns in zip(cont['Precinct'], cont['Neighbors']):\n",
    "        try:\n",
    "            neigh_map[p] = ast.literal_eval(ns)\n",
    "        except:\n",
    "            neigh_map[p] = []\n",
    "\n",
    "    # population lookup\n",
    "    pop_map = dict(zip(\n",
    "        precinct_data[\"GEOID20\"],\n",
    "        precinct_data[\"Total_2020_Total\"]\n",
    "    ))\n",
    "\n",
    "    total_pop = sum(pop_map.values())\n",
    "    ideal_pop = total_pop / K  # ideal district size\n",
    "\n",
    "    # --- STATE ---\n",
    "    assigned = set()\n",
    "    district_pop = {d: 0 for d in district_ids}\n",
    "\n",
    "    # queues: but now neighbors inside each queue will be sorted by pop\n",
    "    queues = {d: deque() for d in district_ids}\n",
    "\n",
    "    # seed assignments\n",
    "    for d, seed in zip(district_ids, seed_geoids):\n",
    "        assignment.loc[assignment['GEOID20'] == seed, \"District\"] = d\n",
    "        assigned.add(seed)\n",
    "        queues[d].append(seed)\n",
    "        district_pop[d] += pop_map.get(seed, 0)\n",
    "\n",
    "    total_precincts = len(assignment)\n",
    "\n",
    "    # ---------- MAIN LOOP -------------\n",
    "    while len(assigned) < total_precincts:\n",
    "        # Prioritize districts most under ideal population\n",
    "        sorted_districts = sorted(district_ids, key=lambda d: ideal_pop - district_pop[d], reverse=True)\n",
    "\n",
    "        for d in sorted_districts:\n",
    "\n",
    "            if len(assigned) >= total_precincts:\n",
    "                break\n",
    "\n",
    "            if not queues[d]:\n",
    "                continue\n",
    "\n",
    "            curr = queues[d].popleft()\n",
    "            neighbors = [nb for nb in neigh_map.get(curr, []) if nb not in assigned]\n",
    "            if not neighbors:\n",
    "                continue\n",
    "\n",
    "            deficit = ideal_pop - district_pop[d]\n",
    "            pop_weight = 3.0  #weight value\n",
    "\n",
    "            def score_neighbor(g):\n",
    "                pop = pop_map.get(g, 0)\n",
    "                if deficit > 0:\n",
    "                    return pop * pop_weight -deficit\n",
    "                else:\n",
    "                    return -pop * pop_weight - deficit\n",
    "\n",
    "            neighbors_sorted = sorted(neighbors, key=score_neighbor, reverse=True)\n",
    "\n",
    "            # If d is below ideal_pop pick large precincts first  \n",
    "            # If d is above ideal_pop pick small precincts first\n",
    "\n",
    "            # assign neighbors in that priority order\n",
    "            for nb in neighbors_sorted:\n",
    "                if nb in assigned:\n",
    "                    continue\n",
    "\n",
    "                assignment.loc[assignment['GEOID20'] == nb, \"District\"] = d\n",
    "                assigned.add(nb)\n",
    "                queues[d].append(nb)\n",
    "                district_pop[d] += pop_map.get(nb, 0)\n",
    "\n",
    "    return assignment, district_pop, ideal_pop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbfb9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "868a6ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 637439  vs ideal  774082.8333333334\n",
      "Contiguous?  True\n",
      "2 533174  vs ideal  774082.8333333334\n",
      "Contiguous?  True\n",
      "3 1227340  vs ideal  774082.8333333334\n",
      "Contiguous?  True\n",
      "4 633440  vs ideal  774082.8333333334\n",
      "Contiguous?  True\n",
      "5 798547  vs ideal  774082.8333333334\n",
      "Contiguous?  True\n",
      "6 901595  vs ideal  774082.8333333334\n",
      "Contiguous?  True\n",
      "7 897636  vs ideal  774082.8333333334\n",
      "Contiguous?  True\n",
      "8 1045843  vs ideal  774082.8333333334\n",
      "Contiguous?  True\n",
      "9 576731  vs ideal  774082.8333333334\n",
      "Contiguous?  True\n",
      "10 651095  vs ideal  774082.8333333334\n",
      "Contiguous?  True\n",
      "11 822556  vs ideal  774082.8333333334\n",
      "Contiguous?  True\n",
      "12 563598  vs ideal  774082.8333333334\n",
      "Contiguous?  True\n"
     ]
    }
   ],
   "source": [
    "seeds = select_population_balanced_seeds(nj_precinct_data, nj_precinct_boundaries, nj_contiguity, num_districts=12)\n",
    "balanced_assignment, pops, target = round_robin_balanced(\n",
    "    nj_current_assignment,\n",
    "    nj_contiguity,\n",
    "    seeds,\n",
    "    nj_precinct_data\n",
    ")\n",
    "for d in range(1, 13):\n",
    "    print(d, pops[d], \" vs ideal \", target)\n",
    "    print(\"Contiguous? \", isDistrictContiguous(d, balanced_assignment, nj_contiguity))\n",
    "balanced_assignment.to_csv(\"district_assignment_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fda189-958e-4639-8c9e-78d618ea055c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21554762",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d65247-a691-4305-a09c-2904846c5218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
