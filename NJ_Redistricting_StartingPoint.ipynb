{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa0c8991",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d053be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9044994",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a92056",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417b53b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c0d7e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a3d493-83fb-4965-bdcb-f1054425e86e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install geojson\n",
    "!pip install shapely\n",
    "!pip install PyShp\n",
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a7f250-1f24-4f02-832b-1df2dceaa50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import csv\n",
    "import ast\n",
    "import shapefile as shp\n",
    "from shapely.geometry import Polygon,shape,MultiPolygon\n",
    "import shapely.ops\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1549e7-0856-443a-aedc-df06d9caf33a",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad28b0c5-f5b6-4baf-9295-07dbff55df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isDistrictContiguous(district_num, assignment, contiguity_list, print_isolates=False, ignore_list=[]):\n",
    "    ## input:\n",
    "    ## district_num: the district number\n",
    "    ## assignment: the assignment from precinct to district\n",
    "    ## contiguity_list: the list of neighbors for each precinct, from the csv file\n",
    "    contiguity_list.columns = ['Precinct','Neighbors']\n",
    "    district_graph = nx.Graph() #creates an empty undirected graph\n",
    "    district_nodes = assignment[assignment['District']==district_num]['GEOID20'].tolist()\n",
    "    for i in ignore_list:\n",
    "        try:\n",
    "            district_nodes.remove(i)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    district_graph.add_nodes_from(district_nodes)\n",
    "    for id in district_nodes:\n",
    "        neighbors = ast.literal_eval(contiguity_list[contiguity_list['Precinct']==id]['Neighbors'].values.tolist()[0])\n",
    "        # needed to convert string to list because the csv encodes the list as a string\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor in district_nodes:\n",
    "                district_graph.add_edge(id,neighbor)\n",
    "    if(print_isolates):\n",
    "        print(list(nx.isolates(district_graph)))\n",
    "    return nx.is_connected(district_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "474da28a-35a4-4115-b19e-9439d1044e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistrictPopulations(assignment,data_file, num_district):\n",
    "    population = {}\n",
    "    for i in range (1,num_district+1):\n",
    "        population[i] = data_file[data_file['GEOID20'].isin(assignment[assignment['District']==i]['GEOID20'])]['Total_2020_Total'].sum()\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c27697-04a7-4169-843b-ce2d98622efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistrictShape(district_id, assignment, boundaries):\n",
    "    list_precincts = assignment[assignment['District']==district_id]['GEOID20']\n",
    "    precinct_shapes = []\n",
    "    for i in list_precincts:\n",
    "        if shape(boundaries[i]).geom_type == 'Polygon':\n",
    "            precinct_shapes.append(Polygon(shape(boundaries[i])))\n",
    "        elif shape(boundaries[i]).geom_type == 'MultiPolygon':\n",
    "            precinct_shapes.append(MultiPolygon(shape(boundaries[i])))      \n",
    "    district_shape = shapely.ops.unary_union(precinct_shapes)\n",
    "    #print(district_shape)\n",
    "    return district_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5e8260f-2f6a-497e-8ff6-51dd9a767180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_compactness(geom): # Polsby-Popper\n",
    "    p = geom.length\n",
    "    a = geom.area    \n",
    "    return (4*np.pi*a)/(p*p)\n",
    "\n",
    "def box_reock_compactness(geom): # Reock on a rectangle bounding box\n",
    "    a = geom.area \n",
    "    bb = geom.bounds # bounds gives you the minimum bounding box (rectangle)\n",
    "    bba = abs(bb[0]-bb[2])*abs(bb[1]-bb[3])\n",
    "    return a/bba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959227a9-93f8-47fa-87ef-02037facafb9",
   "metadata": {},
   "source": [
    "# This Notebook will help you get started on NJ\n",
    "The data is in Canvas, you should upload it to your Google Drive first (if using Colab), or local filesystem (if using Jupyter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69143d08-629d-436a-8687-7a5d3bcb5aa3",
   "metadata": {},
   "source": [
    "### This is the current assignment of precinct to congressional districts (12 of them for NJ)\n",
    "Note that the map shown in DRA is slightly different. This is because some precincts are split in the real assignment, and some additional precinct are created to handle special situations such as prisoners and overseas citizens. You can ignore this for the class project and just use the data and functions provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c2b03-9b2f-46c5-b619-0709ca555c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nj_current_assignment = pd.read_csv('Map_Data/precinct-assignments-congress-nj.csv')\n",
    "nj_current_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6bce06-2f20-4f82-959e-a95f91e25ba5",
   "metadata": {},
   "source": [
    "### This is the current demographic and voter data\n",
    "The data has a lot of attributes that lists voters of different demographics and parties in different elections. You can look at the data Dictionary on Canvas to get details. For this recitation we will only keep votes from the 2020  presidential election and the total 2020 population counts. You can use additional columns (e.g., Governor's elections results, voting age (VAP) population counts, or the composite Dem/Rep score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13a23f-3b65-4852-a42d-3a87867f3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "nj_precinct_data = pd.read_csv('Map_Data/precinct-data-congress-nj.csv')\n",
    "keepcolumns = ['GEOID20','District','Total_2020_Pres','Dem_2020_Pres','Rep_2020_Pres','Total_2020_Total','White_2020_Total','Hispanic_2020_Total','Black_2020_Total','Asian_2020_Total','Native_2020_Total','Pacific_2020_Total']\n",
    "nj_precinct_data = nj_precinct_data[keepcolumns]\n",
    "nj_precinct_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e75d5-6d29-4ab2-ab58-39c67f8b79f1",
   "metadata": {},
   "source": [
    "### This is the precinct boundary data (uses shapely)\n",
    "\n",
    "This is data that represents the geography of the districts. It is needed to test for contiguity, or for any districting partitioning method based on geography. The data is in Shapely format. Each district is represented as a set of points that are connected to create the district shape (in the long/lat coordinates). Shapely geometric functions can be used to compare the shapes. These can be quite inefficient to run, so I am also providing you a pre-computed index that, for each district, lists the districts that are contiguous to it. You can see the code to generate the index in Contiguity.ipynb.\n",
    "\n",
    "To manipulate the shapes, cast them into Shapely Polygons (see example below) and you can use the Polygon properties and functions: https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html#shapely.Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd3dbde7-e314-4fe0-9861-969d96e13645",
   "metadata": {},
   "outputs": [],
   "source": [
    "shpfile = 'Map_Data/nj_vtd_2020_bound/nj_vtd_2020_bound.shp'\n",
    "dbffile = 'Map_Data/nj_vtd_2020_bound/nj_vtd_2020_bound.dbf'\n",
    "shxfile = 'Map_Data/nj_vtd_2020_bound/nj_vtd_2020_bound.shx'\n",
    "\n",
    "\n",
    "shpfile = shp.Reader(shp=shpfile, shx=shxfile, dbf=dbffile)\n",
    "nj_precinct_boundaries={}\n",
    "for sr in shpfile.iterShapeRecords():\n",
    "    geom = sr.shape # get geo bit\n",
    "    rec = sr.record # get db fields\n",
    "    nj_precinct_boundaries[rec[3]]=geom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a473b-0936-4c0e-93cc-850329eaa553",
   "metadata": {},
   "source": [
    "### This is the precinct boundary data \n",
    "\n",
    "This use the contiguity index I have pre-computed using Contiguity.ipynb, that is stored in Contiguity_nj.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c9f089-caad-45b3-b795-71793bcfedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nj_contiguity = pd.read_csv('Contiguity_nj.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c4cda-bb3c-4392-9df0-5e075c19c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,13):\n",
    "    print(\"District \"+str(i)+\" \"+str(isDistrictContiguous(i, nj_current_assignment, nj_contiguity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bad083-6853-462f-be62-38ff2f84e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compactness of the current assignment\n",
    "for district in range(1,13):\n",
    "    print(\"D\"+str(district)+\" PP : \"+str(pp_compactness(getDistrictShape(district,nj_current_assignment,nj_precinct_boundaries))))\n",
    "    print(\"D\"+str(district)+\" BR : \"+str(box_reock_compactness(getDistrictShape(district,nj_current_assignment,nj_precinct_boundaries))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f2ef1-b4be-4c73-b87a-f6e9f6e9b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# District Population of the current assignment\n",
    "print(getDistrictPopulations(nj_current_assignment,nj_precinct_data, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e696388-313f-4090-9035-09a7da258a19",
   "metadata": {},
   "source": [
    "# A simple geographical  redistricting strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ced817-48c2-4b56-8a46-c274e5b9ff7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can create a simple geopgraphical map, like we did for NH. In this case, we have 12 districts, so let's splitting the district in half North/South, and in 6th  East/West. \n",
    "New Hampshire's bounding box is (-75.559614,38.928519,-73.893979,41.357423) (https://anthonylouisdagostino.com/bounding-boxes-for-all-us-states/)\n",
    "So let's start by splitting the state approximately though the middle longitude (-74.72) : everything west of longitude -71.583934 is in odd Districts, everything east is in even Districts. We will use the precinct centroids to assign them. Then we will divide each half per latitude on the ranges  (38.92, 39.3, 39.7, 40.1, 40.5,40.9,41.35)\n",
    "Import the Map to DRA to look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da30c782-b466-47d7-bb37-78b3cad6bd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nj_longlat_assignment = nj_current_assignment.copy()\n",
    "nj_longlat_assignment['District'] = 0\n",
    "for index, row in nj_longlat_assignment.iterrows():\n",
    "    try:\n",
    "        if shape(nj_precinct_boundaries[row['GEOID20']]).geom_type == 'Polygon':\n",
    "            centroid = Polygon(shape(nj_precinct_boundaries[row['GEOID20']])).centroid\n",
    "        elif shape(nj_precinct_boundaries[row['GEOID20']]).geom_type == 'MultiPolygon':\n",
    "            centroid = MultiPolygon(shape(nj_precinct_boundaries[row['GEOID20']])).centroid\n",
    "        else:\n",
    "            print(shape(nj_precinct_boundaries[row['GEOID20']]).geom_type)\n",
    "            pass\n",
    "        if centroid.x <= -74.72:\n",
    "            if centroid.y <= 39.3:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 1\n",
    "            elif centroid.y <= 39.7:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 3\n",
    "            elif centroid.y <= 40.1:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 5\n",
    "            elif centroid.y <= 40.5:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 7\n",
    "            elif centroid.y <= 40.9:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 9\n",
    "            else:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 11\n",
    "        else:\n",
    "            if centroid.y <= 39.3:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 2\n",
    "            elif centroid.y <= 39.7:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 4\n",
    "            elif centroid.y <= 40.1:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 6\n",
    "            elif centroid.y <= 40.5:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 8\n",
    "            elif centroid.y <= 40.9:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 10\n",
    "            else:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 12\n",
    "    except KeyError: \n",
    "        pass\n",
    "#print(nh_longitude_assignment)\n",
    "nj_longlat_assignment.to_csv('Recitation maps/nj_longlat_map.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb00508f-3df2-487c-90ac-56a7af050c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compactness of this Longlat assignment\n",
    "for district in range(1,13):\n",
    "    print(\"D\"+str(district)+\" PP : \"+str(pp_compactness(getDistrictShape(district,nj_longlat_assignment,nj_precinct_boundaries))))\n",
    "    print(\"D\"+str(district)+\" BR : \"+str(box_reock_compactness(getDistrictShape(district,nj_longlat_assignment,nj_precinct_boundaries))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c674a-6122-4440-a87a-9b5b4250f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# District Population of this longlat assignment\n",
    "print(getDistrictPopulations(nj_longlat_assignment,nj_precinct_data, 12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f943977-f3a0-41b8-930e-6e26d74092f2",
   "metadata": {},
   "source": [
    "# Now create your own redistricting maps\n",
    "Remember to check for contiguity, and to ensure that the population of the districts are balanced (which is not the case in the example above.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840daff",
   "metadata": {},
   "source": [
    "## Fair Map Seeding Algorithm\n",
    "\n",
    "This section implements the seeding algorithm for the fair map. The goal is to select 12 initial seed precincts (one per district) that are:\n",
    "- Geographically spread out across the state\n",
    "- Have population sizes initially close to the average precinct population\n",
    "- Consider demographic trends and try to pair demographic groups \n",
    "- Not biased towards any political party \n",
    "- Located in areas that allow for compact district growth\n",
    "\n",
    "- Since final population of each district should be around NJPopulation/12.\n",
    "- The seed population of each district should be 10% of NJ Population/12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830bfb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precinct_centroid(geoid, boundaries):\n",
    "    \"\"\"Get the centroid coordinates for a single precinct.\"\"\"\n",
    "    try:\n",
    "        if shape(boundaries[geoid]).geom_type == 'Polygon':\n",
    "            centroid = Polygon(shape(boundaries[geoid])).centroid\n",
    "        elif shape(boundaries[geoid]).geom_type == 'MultiPolygon':\n",
    "            centroid = MultiPolygon(shape(boundaries[geoid])).centroid\n",
    "        else:\n",
    "            return None\n",
    "        return (centroid.x, centroid.y)  # (longitude, latitude)\n",
    "    except (KeyError, Exception):\n",
    "        return None\n",
    "\n",
    "def get_district_centroid(district_id, assignment, boundaries):\n",
    "    \"\"\"Get the centroid coordinates for a district (all precincts in that district).\"\"\"\n",
    "    district_precincts = assignment[assignment['District'] == district_id]['GEOID20'].tolist()\n",
    "    precinct_centroids = []\n",
    "    for geoid in district_precincts:\n",
    "        centroid = get_precinct_centroid(geoid, boundaries)\n",
    "        if centroid:\n",
    "            precinct_centroids.append(centroid)\n",
    "    \n",
    "    if not precinct_centroids:\n",
    "        return None\n",
    "    \n",
    "    # Calculate average centroid (simple approach)\n",
    "    avg_lon = sum(c[0] for c in precinct_centroids) / len(precinct_centroids)\n",
    "    avg_lat = sum(c[1] for c in precinct_centroids) / len(precinct_centroids)\n",
    "    return (avg_lon, avg_lat)\n",
    "\n",
    "def get_precinct_neighbors(geoid, contiguity_df):\n",
    "    \"\"\"Get the list of neighboring precincts for a given precinct.\"\"\"\n",
    "    df = contiguity_df.copy()\n",
    "    df.columns = ['Precinct', 'Neighbors']\n",
    "    try:\n",
    "        neighbors_str = df[df['Precinct'] == geoid]['Neighbors'].values[0]\n",
    "        return ast.literal_eval(neighbors_str)\n",
    "    except (KeyError, IndexError, ValueError):\n",
    "        return []\n",
    "\n",
    "\n",
    "total_nj_population = nj_precinct_data['Total_2020_Total'].sum()\n",
    "avg_district_population = total_nj_population / 12\n",
    "advisedSeedPopulation = avg_district_population * 0.10\n",
    "\n",
    "def select_fair_seeds(precinct_data, boundaries, contiguity_df, num_districts=12):\n",
    "    \"\"\"\n",
    "    Select seed precincts for a fair redistricting map.\n",
    "    \n",
    "    Strategy:\n",
    "    1. Divide the state into num_districts roughly equal geographic regions\n",
    "    1a. Because some districts will be \"physically bigger in size\" we will try to split the regions by population\n",
    "    2. For each region, select a initial seed precinct that:\n",
    "       - Is near the center of that region and contiguous\n",
    "       - Has neighbors available for growth\n",
    "    3. Flood fill up to advisedSeedPopulation\n",
    "        - Population constraint of up to advisedSeedPopulation\n",
    "        - contiguity constraint\n",
    "        - Keep geographic constraint by adding precincts close to get_District_centroid()\n",
    "        - Let's just initially try to focus on adding communities of interest for this seeding flood fill\n",
    "\n",
    "    \"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbbee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a6ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fda189-958e-4639-8c9e-78d618ea055c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d65247-a691-4305-a09c-2904846c5218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow GPU",
   "language": "python",
   "name": "tf_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
